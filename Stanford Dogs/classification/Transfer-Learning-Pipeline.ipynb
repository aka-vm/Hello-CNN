{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer-Learning-Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pipeline Contains The Implementation of 12 Transfer Learning Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go to parent directory\n",
    "os.chdir(\"../..\")\n",
    "import paths\n",
    "\n",
    "REPO_DIR = paths.get_repo_path()\n",
    "ROOT_DIR = REPO_DIR / \"Stanford Dogs\"\n",
    "DATA_BASE_PATH = paths.get_data_path() / \"stanford-dogs-dataset\"\n",
    "DATA_PATH = DATA_BASE_PATH / \"splited-data\"\n",
    "\n",
    "TRAIN_PATH = DATA_PATH / \"train\"\n",
    "TEST_PATH = DATA_PATH / \"test\"\n",
    "\n",
    "# set path to repo_dir\n",
    "os.chdir(REPO_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "IMAGE_WIDTH = 224\n",
    "IMAGE_HEIGHT = 224\n",
    "\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "CLASS_NAMES = sorted([img_cls for img_cls in  os.listdir(TRAIN_PATH) if img_cls != \".DS_Store\"])\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "# MODEL\n",
    "MODEL_PATH = ROOT_DIR / \"models\"\n",
    "LOG_PATH = ROOT_DIR / \"log\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_generator = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    \n",
    "    horizontal_flip=True,\n",
    "    \n",
    "    rotation_range=20,\n",
    "    \n",
    "    height_shift_range=0.1,       # No need to shift the image\n",
    "    width_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    \n",
    "    shear_range=0.1,              # Seems to be useful\n",
    "    \n",
    "    validation_split=VALIDATION_SPLIT,\n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    )\n",
    "\n",
    "test_generator = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_generator.flow_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    \n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    \n",
    "    subset='training',\n",
    ")\n",
    "\n",
    "val_images = val_generator.flow_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    \n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    \n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "\n",
    "test_images = test_generator.flow_from_directory(\n",
    "    TEST_PATH,\n",
    "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    \n",
    "    batch_size=BATCH_SIZE,\n",
    "    \n",
    "    shuffle=False,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "NUM_TRAIN_IMAGES = len(train_images.filenames)\n",
    "NUM_VAL_IMAGES = len(val_images.filenames)\n",
    "NUM_TEST_IMAGES = len(test_images.filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def give_class_name(y:np.ndarray) -> np.ndarray:\n",
    "    if len(y.shape) == 2:\n",
    "        y = y.argmax(axis=1)\n",
    "    enc = LabelEncoder().fit(CLASS_NAMES)\n",
    "    y_labeled = enc.inverse_transform(y)\n",
    "    \n",
    "    return y_labeled\n",
    "\n",
    "# display images in a grid function\n",
    "def display_image_grid(images, labels, pred_val=None,shape=(5, 5), figsize=(10, 10)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    m = shape[0] * shape[1]\n",
    "    \n",
    "    if images.shape[0] < m:\n",
    "        raise ValueError(\"images.shape[0] must equal shape[0] * shape[1]\")\n",
    "    \n",
    "    if labels.shape[0] != images.shape[0]:\n",
    "        raise ValueError(\"labels.shape[0] must equal images.shape[0]\")\n",
    "    \n",
    "    if pred_val is not None and pred_val.shape[0] != images.shape[0]:\n",
    "        raise ValueError(\"pred_val.shape[0] must equal images.shape[0]\")\n",
    "    \n",
    "    for i in range(m):\n",
    "        plt.subplot(shape[0], shape[1], i+1)\n",
    "        plt.imshow(images[i], cmap=\"gray\", interpolation=\"none\")\n",
    "        title = labels[i]\n",
    "        if pred_val is not None:\n",
    "            title = f\"{pred_val[i]}\"\n",
    "            if pred_val[i] != labels[i]:\n",
    "                title += f\"\\n*({labels[i]})*\"\n",
    "        plt.title(title)\n",
    "        plt.axis(\"off\")\n",
    "        # increase vertical space between subplots\n",
    "        plt.subplots_adjust(wspace=0.1, hspace=0.4)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 8\n",
    "num_cols = 8\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "images, labels = train_images.next()\n",
    "for i in range(num_cols * num_rows):\n",
    "    plt.subplot(num_cols, num_rows, i + 1)\n",
    "    plt.imshow(images[i])\n",
    "    plt.title(CLASS_NAMES[labels[i].argmax()])\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, Rescaling, Input, Add, Activation, BatchNormalization, AveragePooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score, precision_score, recall_score, log_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valribles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = train_images.next()[0][0].shape\n",
    "TRAIN_MODELS = True\n",
    "# TRAIN_MODELS = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful functions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import top_k_categorical_accuracy\n",
    "\n",
    "def predict_label(images, model):\n",
    "    predictions = model.predict(images)\n",
    "    return predictions.argmax(axis=1)\n",
    "\n",
    "\n",
    "# ploting the model training history\n",
    "def plot_model_performance(history, figsize=(10, 10)):\n",
    "    preformance = {key: val for key, val in history.history.items() if \"loss\" not in key}\n",
    "    losses = {key: val for key, val in history.history.items() if \"loss\" in key}\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.title('Model Performance')\n",
    "    for key, val in preformance.items():\n",
    "        plt.plot(val, label=key)\n",
    "    plt.legend(preformance.keys())\n",
    "    plt.xlabel('Epoch')\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.title('Model Losses')\n",
    "    for key, val in losses.items():\n",
    "        plt.plot(val, label=key)\n",
    "    plt.legend(losses.keys())\n",
    "    plt.xlabel('Epoch')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# def get_model_performance(y_true, y_pred):\n",
    "#     if len(y_true.shape) == 2:\n",
    "#         y_true = y_true.argmax(axis=1)\n",
    "#     if len(y_pred.shape) == 2:\n",
    "#         y_pred = y_pred.argmax(axis=1)\n",
    "\n",
    "#     accuracy = accuracy_score(y_true, y_pred)\n",
    "#     # top_5_accuracy = top_k_categorical_accuracy(y_true, y_pred, k=5)\n",
    "#     f1_scr = f1_score(y_true, y_pred, average='weighted')\n",
    "#     precision_scr = precision_score(y_true, y_pred, average='weighted')\n",
    "#     recall_scr = recall_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    \n",
    "#     performance = {\n",
    "#         \"Accuracy\": accuracy,\n",
    "#         # \"top-5-accuracy\": top_5_accuracy,\n",
    "#         \"F1 Score\": f1_scr,\n",
    "#         \"Precision\": precision_scr,\n",
    "#         \"Recall\": recall_scr\n",
    "#     }\n",
    "    \n",
    "#     return performance\n",
    "def compute_performance_metrics(y, y_pred, print_report=True):\n",
    "    # labels = test_images_.y.argmax(axis=1)\n",
    "    labels = y\n",
    "    labels_cat = tf.keras.utils.to_categorical(labels, NUM_CLASSES)\n",
    "    # pred_cat = model.predict(test_images_)\n",
    "    pred_cat = y_pred\n",
    "    pred = pred_cat.argmax(axis=1)\n",
    "\n",
    "    \n",
    "    performance_metrics = {}\n",
    "    performance_metrics[\"accuracy\"] = accuracy_score(labels, pred)\n",
    "    performance_metrics[\"top_5_accuracy\"] = top_k_categorical_accuracy(labels_cat, pred_cat, k=5).numpy().sum() / len(y)\n",
    "    performance_metrics[\"f1_score\"] = f1_score(labels, pred, average=\"macro\")\n",
    "    performance_metrics[\"precision\"] = precision_score(labels, pred, average=\"macro\")\n",
    "    performance_metrics[\"recall\"] = recall_score(labels, pred, average=\"macro\")\n",
    "    performance_metrics[\"loss\"] = log_loss(labels_cat, pred_cat)\n",
    "    \n",
    "    performance_df.loc[model.name] = performance_metrics\n",
    "    if print_report:\n",
    "        return performance_df.loc[model.name]\n",
    "\n",
    "performance_df = pd.DataFrame(columns=[\"accuracy\", \"top_5_accuracy\", \"precision\", \"recall\", \"f1_score\", \"loss\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import applications\n",
    "\n",
    "weight_decay = 1e-5\n",
    "LEARNING_RATE = 4e-4\n",
    "learning_rate_decay_rate = 0.1\n",
    "\n",
    "def create_model(model_backbone: str, model_name:str=None, layers=[256]):\n",
    "    model_name = model_name or model_backbone\n",
    "    model = Sequential(name=model_name)\n",
    "    \n",
    "    model_backbone = get_model_backbone(model_backbone)\n",
    "    model_backbone.trainable = False\n",
    "    model.add(model_backbone)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    for layer_size in layers:\n",
    "        model.add(Dense(layer_size, kernel_regularizer=l2(weight_decay)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_model_backbone(model_backbone: str):\n",
    "    if model_backbone == \"VGG16\":\n",
    "        model_backbone = applications.VGG16(include_top=False, weights='imagenet', input_shape=INPUT_SHAPE)\n",
    "    elif model_backbone == \"VGG19\":\n",
    "        model_backbone = applications.VGG19(include_top=False, weights='imagenet', input_shape=INPUT_SHAPE)\n",
    "    elif model_backbone == \"ResNet50V2\":\n",
    "        model_backbone = applications.ResNet50V2(include_top=False, weights='imagenet', input_shape=INPUT_SHAPE)\n",
    "    elif model_backbone == \"ResNet101V2\":\n",
    "        model_backbone = applications.ResNet101V2(include_top=False, weights='imagenet', input_shape=INPUT_SHAPE)\n",
    "    elif model_backbone == \"ResNet152V2\":\n",
    "        model_backbone = applications.ResNet152V2(include_top=False, weights='imagenet', input_shape=INPUT_SHAPE)\n",
    "    elif model_backbone == \"InceptionV3\":\n",
    "        model_backbone = applications.InceptionV3(include_top=False, weights='imagenet', input_shape=INPUT_SHAPE)\n",
    "    elif model_backbone == \"InceptionResNetV2\":\n",
    "        model_backbone = applications.InceptionResNetV2(include_top=False, weights='imagenet', input_shape=INPUT_SHAPE)\n",
    "    elif model_backbone == \"Xception\":\n",
    "        model_backbone = applications.Xception(include_top=False, weights='imagenet', input_shape=INPUT_SHAPE)\n",
    "    elif model_backbone == \"DenselNet121\":\n",
    "        model_backbone = applications.DenseNet121(include_top=False, weights='imagenet', input_shape=INPUT_SHAPE)\n",
    "    elif model_backbone == \"DenselNet169\":\n",
    "        model_backbone = applications.DenseNet169(include_top=False, weights='imagenet', input_shape=INPUT_SHAPE)\n",
    "    elif model_backbone == \"DenselNet201\":\n",
    "        model_backbone = applications.DenseNet201(include_top=False, weights='imagenet', input_shape=INPUT_SHAPE)\n",
    "    elif model_backbone == \"MobileNet\":\n",
    "        model_backbone = applications.MobileNet(include_top=False, weights='imagenet', input_shape=INPUT_SHAPE)\n",
    "    elif model_backbone == \"MobileNetV2\":\n",
    "        model_backbone = applications.MobileNetV2(include_top=False, weights='imagenet', input_shape=INPUT_SHAPE)\n",
    "        \n",
    "    return model_backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint, CSVLogger\n",
    "\n",
    "\n",
    "monitor_metric = 'val_accuracy'\n",
    "# learning_rate_decay_rate = 0.06\n",
    "def get_callbacks():\n",
    "    callbacks = {}\n",
    "    \n",
    "    callbacks[\"EarlyStopping\"] = EarlyStopping(\n",
    "            monitor=monitor_metric,\n",
    "            patience=6,\n",
    "            mode = \"auto\",\n",
    "            verbose=1,\n",
    "        )\n",
    "    \n",
    "    callbacks[\"LearningRateScheduler\"] = LearningRateScheduler(step_decay)\n",
    "\n",
    "    callbacks[\"ModelCheckpoint\"] = ModelCheckpoint(\n",
    "            MODEL_PATH / f\"{model.name}.h5\",\n",
    "            monitor=monitor_metric,\n",
    "            save_best_only=True,\n",
    "            mode='auto',\n",
    "            verbose=1,\n",
    "    )\n",
    "    \n",
    "    return callbacks\n",
    "\n",
    "\n",
    "def step_decay(epoch):\n",
    "    initial_lr = LEARNING_RATE\n",
    "    k = learning_rate_decay_rate\n",
    "    lr = initial_lr * np.exp(-k*epoch)\n",
    "    return lr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_model = \"VGG16\"\n",
    "model = create_model(backbone_model, layers=[512])\n",
    "# LEARNING_RATE = 4e-5\n",
    "# learning_rate_decay_rate = 0.07\n",
    "\n",
    "callbacks = [callback for callback in get_callbacks().values()]\n",
    "\n",
    "model.compile(\n",
    "        optimizer=Adam(\n",
    "            learning_rate=LEARNING_RATE\n",
    "            ), \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            'top_k_categorical_accuracy',\n",
    "            ]\n",
    "        )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "train_model = not (os.path.exists(MODEL_PATH / f\"{model.name}.h5\")) or TRAIN_MODELS\n",
    "\n",
    "if train_model:\n",
    "    history = model.fit(train_images, \n",
    "                        validation_data=val_images,\n",
    "                        epochs=50, \n",
    "                        callbacks=callbacks,                        \n",
    "    )\n",
    "else:\n",
    "    model_path = MODEL_PATH / f\"{model.name}.h5\"\n",
    "    model = load_model(model_path)\n",
    "    print(f\"{model.name} model loaded from {model_path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model:\n",
    "    model.evaluate(test_images)\n",
    "    plot_model_performance(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images.shuffle = False\n",
    "test_labels = test_images.labels\n",
    "test_labels_pred_ohe = model.predict(test_images)\n",
    "test_labels_pred = test_labels_pred_ohe.argmax(axis=1)\n",
    "compute_performance_metrics(test_labels, test_labels_pred_ohe, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_model = \"VGG19\"\n",
    "model = create_model(backbone_model, layers=[512])\n",
    "# LEARNING_RATE = 4e-5\n",
    "# learning_rate_decay_rate = 0.07\n",
    "\n",
    "callbacks = [callback for callback in get_callbacks().values()]\n",
    "\n",
    "model.compile(\n",
    "        optimizer=Adam(\n",
    "            learning_rate=LEARNING_RATE\n",
    "            ), \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            'top_k_categorical_accuracy',\n",
    "            ]\n",
    "        )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "train_model = not (os.path.exists(MODEL_PATH / f\"{model.name}.h5\")) or TRAIN_MODELS\n",
    "\n",
    "if train_model:\n",
    "    history = model.fit(train_images, \n",
    "                        validation_data=val_images,\n",
    "                        epochs=50, \n",
    "                        callbacks=callbacks,                        \n",
    "    )\n",
    "else:\n",
    "    model_path = MODEL_PATH / f\"{model.name}.h5\"\n",
    "    model = load_model(model_path)\n",
    "    print(f\"{model.name} model loaded from {model_path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model:\n",
    "    model.evaluate(test_images)\n",
    "    plot_model_performance(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images.shuffle = False\n",
    "test_labels = test_images.labels\n",
    "test_labels_pred_ohe = model.predict(test_images)\n",
    "test_labels_pred = test_labels_pred_ohe.argmax(axis=1)\n",
    "compute_performance_metrics(test_labels, test_labels_pred_ohe, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_model = \"ResNet50V2\"\n",
    "model = create_model(backbone_model, layers=[512])\n",
    "# LEARNING_RATE = 4e-5\n",
    "# learning_rate_decay_rate = 0.07\n",
    "\n",
    "callbacks = [callback for callback in get_callbacks().values()]\n",
    "\n",
    "model.compile(\n",
    "        optimizer=Adam(\n",
    "            learning_rate=LEARNING_RATE\n",
    "            ), \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            'top_k_categorical_accuracy',\n",
    "            ]\n",
    "        )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "train_model = not (os.path.exists(MODEL_PATH / f\"{model.name}.h5\")) or TRAIN_MODELS\n",
    "\n",
    "if train_model:\n",
    "    history = model.fit(train_images, \n",
    "                        validation_data=val_images,\n",
    "                        epochs=50, \n",
    "                        callbacks=callbacks,                        \n",
    "    )\n",
    "else:\n",
    "    model_path = MODEL_PATH / f\"{model.name}.h5\"\n",
    "    model = load_model(model_path)\n",
    "    print(f\"{model.name} model loaded from {model_path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model:\n",
    "    model.evaluate(test_images)\n",
    "    plot_model_performance(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images.shuffle = False\n",
    "test_labels = test_images.labels\n",
    "test_labels_pred_ohe = model.predict(test_images)\n",
    "test_labels_pred = test_labels_pred_ohe.argmax(axis=1)\n",
    "compute_performance_metrics(test_labels, test_labels_pred_ohe, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ResNet101V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_model = \"ResNet101V2\"\n",
    "model = create_model(backbone_model, layers=[512])\n",
    "# LEARNING_RATE = 4e-5\n",
    "# learning_rate_decay_rate = 0.07\n",
    "\n",
    "callbacks = [callback for callback in get_callbacks().values()]\n",
    "\n",
    "model.compile(\n",
    "        optimizer=Adam(\n",
    "            learning_rate=LEARNING_RATE\n",
    "            ), \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            'top_k_categorical_accuracy',\n",
    "            ]\n",
    "        )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "train_model = not (os.path.exists(MODEL_PATH / f\"{model.name}.h5\")) or TRAIN_MODELS\n",
    "\n",
    "if train_model:\n",
    "    history = model.fit(train_images, \n",
    "                        validation_data=val_images,\n",
    "                        epochs=50, \n",
    "                        callbacks=callbacks,                        \n",
    "    )\n",
    "else:\n",
    "    model_path = MODEL_PATH / f\"{model.name}.h5\"\n",
    "    model = load_model(model_path)\n",
    "    print(f\"{model.name} model loaded from {model_path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model:\n",
    "    model.evaluate(test_images)\n",
    "    plot_model_performance(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images.shuffle = False\n",
    "test_labels = test_images.labels\n",
    "test_labels_pred_ohe = model.predict(test_images)\n",
    "test_labels_pred = test_labels_pred_ohe.argmax(axis=1)\n",
    "compute_performance_metrics(test_labels, test_labels_pred_ohe, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ResNet152V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_model = \"ResNet152V2\"\n",
    "model = create_model(backbone_model, layers=[512])\n",
    "# LEARNING_RATE = 4e-5\n",
    "# learning_rate_decay_rate = 0.07\n",
    "\n",
    "callbacks = [callback for callback in get_callbacks().values()]\n",
    "\n",
    "model.compile(\n",
    "        optimizer=Adam(\n",
    "            learning_rate=LEARNING_RATE\n",
    "            ), \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            'top_k_categorical_accuracy',\n",
    "            ]\n",
    "        )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "train_model = not (os.path.exists(MODEL_PATH / f\"{model.name}.h5\")) or TRAIN_MODELS\n",
    "\n",
    "if train_model:\n",
    "    history = model.fit(train_images, \n",
    "                        validation_data=val_images,\n",
    "                        epochs=50, \n",
    "                        callbacks=callbacks,                        \n",
    "    )\n",
    "else:\n",
    "    model_path = MODEL_PATH / f\"{model.name}.h5\"\n",
    "    model = load_model(model_path)\n",
    "    print(f\"{model.name} model loaded from {model_path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model:\n",
    "    model.evaluate(test_images)\n",
    "    plot_model_performance(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images.shuffle = False\n",
    "test_labels = test_images.labels\n",
    "test_labels_pred_ohe = model.predict(test_images)\n",
    "test_labels_pred = test_labels_pred_ohe.argmax(axis=1)\n",
    "compute_performance_metrics(test_labels, test_labels_pred_ohe, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_model = \"InceptionV3\"\n",
    "model = create_model(backbone_model, layers=[512])\n",
    "# LEARNING_RATE = 4e-5\n",
    "# learning_rate_decay_rate = 0.07\n",
    "\n",
    "callbacks = [callback for callback in get_callbacks().values()]\n",
    "\n",
    "model.compile(\n",
    "        optimizer=Adam(\n",
    "            learning_rate=LEARNING_RATE\n",
    "            ), \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            'top_k_categorical_accuracy',\n",
    "            ]\n",
    "        )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "train_model = not (os.path.exists(MODEL_PATH / f\"{model.name}.h5\")) or TRAIN_MODELS\n",
    "\n",
    "if train_model:\n",
    "    history = model.fit(train_images, \n",
    "                        validation_data=val_images,\n",
    "                        epochs=50, \n",
    "                        callbacks=callbacks,                        \n",
    "    )\n",
    "else:\n",
    "    model_path = MODEL_PATH / f\"{model.name}.h5\"\n",
    "    model = load_model(model_path)\n",
    "    print(f\"{model.name} model loaded from {model_path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model:\n",
    "    model.evaluate(test_images)\n",
    "    plot_model_performance(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images.shuffle = False\n",
    "test_labels = test_images.labels\n",
    "test_labels_pred_ohe = model.predict(test_images)\n",
    "test_labels_pred = test_labels_pred_ohe.argmax(axis=1)\n",
    "compute_performance_metrics(test_labels, test_labels_pred_ohe, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_model = \"InceptionResNetV2\"\n",
    "model = create_model(backbone_model, layers=[512])\n",
    "# LEARNING_RATE = 4e-5\n",
    "# learning_rate_decay_rate = 0.07\n",
    "\n",
    "callbacks = [callback for callback in get_callbacks().values()]\n",
    "\n",
    "model.compile(\n",
    "        optimizer=Adam(\n",
    "            learning_rate=LEARNING_RATE\n",
    "            ), \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            'top_k_categorical_accuracy',\n",
    "            ]\n",
    "        )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "train_model = not (os.path.exists(MODEL_PATH / f\"{model.name}.h5\")) or TRAIN_MODELS\n",
    "\n",
    "if train_model:\n",
    "    history = model.fit(train_images, \n",
    "                        validation_data=val_images,\n",
    "                        epochs=50, \n",
    "                        callbacks=callbacks,                        \n",
    "    )\n",
    "else:\n",
    "    model_path = MODEL_PATH / f\"{model.name}.h5\"\n",
    "    model = load_model(model_path)\n",
    "    print(f\"{model.name} model loaded from {model_path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model:\n",
    "    model.evaluate(test_images)\n",
    "    plot_model_performance(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images.shuffle = False\n",
    "test_labels = test_images.labels\n",
    "test_labels_pred_ohe = model.predict(test_images)\n",
    "test_labels_pred = test_labels_pred_ohe.argmax(axis=1)\n",
    "compute_performance_metrics(test_labels, test_labels_pred_ohe, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_model = \"Xception\"\n",
    "model = create_model(backbone_model, layers=[512])\n",
    "# LEARNING_RATE = 4e-5\n",
    "# learning_rate_decay_rate = 0.07\n",
    "\n",
    "callbacks = [callback for callback in get_callbacks().values()]\n",
    "\n",
    "model.compile(\n",
    "        optimizer=Adam(\n",
    "            learning_rate=LEARNING_RATE\n",
    "            ), \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            'top_k_categorical_accuracy',\n",
    "            ]\n",
    "        )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "train_model = not (os.path.exists(MODEL_PATH / f\"{model.name}.h5\")) or TRAIN_MODELS\n",
    "\n",
    "if train_model:\n",
    "    history = model.fit(train_images, \n",
    "                        validation_data=val_images,\n",
    "                        epochs=50, \n",
    "                        callbacks=callbacks,                        \n",
    "    )\n",
    "else:\n",
    "    model_path = MODEL_PATH / f\"{model.name}.h5\"\n",
    "    model = load_model(model_path)\n",
    "    print(f\"{model.name} model loaded from {model_path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model:\n",
    "    model.evaluate(test_images)\n",
    "    plot_model_performance(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images.shuffle = False\n",
    "test_labels = test_images.labels\n",
    "test_labels_pred_ohe = model.predict(test_images)\n",
    "test_labels_pred = test_labels_pred_ohe.argmax(axis=1)\n",
    "compute_performance_metrics(test_labels, test_labels_pred_ohe, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_model = \"DenseNet121\"\n",
    "model = create_model(backbone_model, layers=[512])\n",
    "# LEARNING_RATE = 4e-5\n",
    "# learning_rate_decay_rate = 0.07\n",
    "\n",
    "callbacks = [callback for callback in get_callbacks().values()]\n",
    "\n",
    "model.compile(\n",
    "        optimizer=Adam(\n",
    "            learning_rate=LEARNING_RATE\n",
    "            ), \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            'top_k_categorical_accuracy',\n",
    "            ]\n",
    "        )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "train_model = not (os.path.exists(MODEL_PATH / f\"{model.name}.h5\")) or TRAIN_MODELS\n",
    "\n",
    "if train_model:\n",
    "    history = model.fit(train_images, \n",
    "                        validation_data=val_images,\n",
    "                        epochs=50, \n",
    "                        callbacks=callbacks,                        \n",
    "    )\n",
    "else:\n",
    "    model_path = MODEL_PATH / f\"{model.name}.h5\"\n",
    "    model = load_model(model_path)\n",
    "    print(f\"{model.name} model loaded from {model_path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model:\n",
    "    model.evaluate(test_images)\n",
    "    plot_model_performance(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images.shuffle = False\n",
    "test_labels = test_images.labels\n",
    "test_labels_pred_ohe = model.predict(test_images)\n",
    "test_labels_pred = test_labels_pred_ohe.argmax(axis=1)\n",
    "compute_performance_metrics(test_labels, test_labels_pred_ohe, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DenseNet169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_model = \"DenseNet169\"\n",
    "model = create_model(backbone_model, layers=[512])\n",
    "# LEARNING_RATE = 4e-5\n",
    "# learning_rate_decay_rate = 0.07\n",
    "\n",
    "callbacks = [callback for callback in get_callbacks().values()]\n",
    "\n",
    "model.compile(\n",
    "        optimizer=Adam(\n",
    "            learning_rate=LEARNING_RATE\n",
    "            ), \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            'top_k_categorical_accuracy',\n",
    "            ]\n",
    "        )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "train_model = not (os.path.exists(MODEL_PATH / f\"{model.name}.h5\")) or TRAIN_MODELS\n",
    "\n",
    "if train_model:\n",
    "    history = model.fit(train_images, \n",
    "                        validation_data=val_images,\n",
    "                        epochs=50, \n",
    "                        callbacks=callbacks,                        \n",
    "    )\n",
    "else:\n",
    "    model_path = MODEL_PATH / f\"{model.name}.h5\"\n",
    "    model = load_model(model_path)\n",
    "    print(f\"{model.name} model loaded from {model_path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model:\n",
    "    model.evaluate(test_images)\n",
    "    plot_model_performance(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images.shuffle = False\n",
    "test_labels = test_images.labels\n",
    "test_labels_pred_ohe = model.predict(test_images)\n",
    "test_labels_pred = test_labels_pred_ohe.argmax(axis=1)\n",
    "compute_performance_metrics(test_labels, test_labels_pred_ohe, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DenseNet201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_model = \"DenseNet201\"\n",
    "model = create_model(backbone_model, layers=[512])\n",
    "# LEARNING_RATE = 4e-5\n",
    "# learning_rate_decay_rate = 0.07\n",
    "\n",
    "callbacks = [callback for callback in get_callbacks().values()]\n",
    "\n",
    "model.compile(\n",
    "        optimizer=Adam(\n",
    "            learning_rate=LEARNING_RATE\n",
    "            ), \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            'top_k_categorical_accuracy',\n",
    "            ]\n",
    "        )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "train_model = not (os.path.exists(MODEL_PATH / f\"{model.name}.h5\")) or TRAIN_MODELS\n",
    "\n",
    "if train_model:\n",
    "    history = model.fit(train_images, \n",
    "                        validation_data=val_images,\n",
    "                        epochs=50, \n",
    "                        callbacks=callbacks,                        \n",
    "    )\n",
    "else:\n",
    "    model_path = MODEL_PATH / f\"{model.name}.h5\"\n",
    "    model = load_model(model_path)\n",
    "    print(f\"{model.name} model loaded from {model_path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model:\n",
    "    model.evaluate(test_images)\n",
    "    plot_model_performance(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images.shuffle = False\n",
    "test_labels = test_images.labels\n",
    "test_labels_pred_ohe = model.predict(test_images)\n",
    "test_labels_pred = test_labels_pred_ohe.argmax(axis=1)\n",
    "compute_performance_metrics(test_labels, test_labels_pred_ohe, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_model = \"MobileNet\"\n",
    "model = create_model(backbone_model, layers=[512])\n",
    "# LEARNING_RATE = 4e-5\n",
    "# learning_rate_decay_rate = 0.07\n",
    "\n",
    "callbacks = [callback for callback in get_callbacks().values()]\n",
    "\n",
    "model.compile(\n",
    "        optimizer=Adam(\n",
    "            learning_rate=LEARNING_RATE\n",
    "            ), \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            'top_k_categorical_accuracy',\n",
    "            ]\n",
    "        )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "train_model = not (os.path.exists(MODEL_PATH / f\"{model.name}.h5\")) or TRAIN_MODELS\n",
    "\n",
    "if train_model:\n",
    "    history = model.fit(train_images, \n",
    "                        validation_data=val_images,\n",
    "                        epochs=50, \n",
    "                        callbacks=callbacks,                        \n",
    "    )\n",
    "else:\n",
    "    model_path = MODEL_PATH / f\"{model.name}.h5\"\n",
    "    model = load_model(model_path)\n",
    "    print(f\"{model.name} model loaded from {model_path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model:\n",
    "    model.evaluate(test_images)\n",
    "    plot_model_performance(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images.shuffle = False\n",
    "test_labels = test_images.labels\n",
    "test_labels_pred_ohe = model.predict(test_images)\n",
    "test_labels_pred = test_labels_pred_ohe.argmax(axis=1)\n",
    "compute_performance_metrics(test_labels, test_labels_pred_ohe, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_model = \"MobileNetV2\"\n",
    "model = create_model(backbone_model, layers=[512])\n",
    "# LEARNING_RATE = 4e-5\n",
    "# learning_rate_decay_rate = 0.07\n",
    "\n",
    "callbacks = [callback for callback in get_callbacks().values()]\n",
    "\n",
    "model.compile(\n",
    "        optimizer=Adam(\n",
    "            learning_rate=LEARNING_RATE\n",
    "            ), \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            'top_k_categorical_accuracy',\n",
    "            ]\n",
    "        )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "train_model = not (os.path.exists(MODEL_PATH / f\"{model.name}.h5\")) or TRAIN_MODELS\n",
    "\n",
    "if train_model:\n",
    "    history = model.fit(train_images, \n",
    "                        validation_data=val_images,\n",
    "                        epochs=50, \n",
    "                        callbacks=callbacks,                        \n",
    "    )\n",
    "else:\n",
    "    model_path = MODEL_PATH / f\"{model.name}.h5\"\n",
    "    model = load_model(model_path)\n",
    "    print(f\"{model.name} model loaded from {model_path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model:\n",
    "    model.evaluate(test_images)\n",
    "    plot_model_performance(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images.shuffle = False\n",
    "test_labels = test_images.labels\n",
    "test_labels_pred_ohe = model.predict(test_images)\n",
    "test_labels_pred = test_labels_pred_ohe.argmax(axis=1)\n",
    "compute_performance_metrics(test_labels, test_labels_pred_ohe, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ed7427108cb8ee2bab4a987d0bb01f599fbd29a8099bcba187724d3c7a723ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
