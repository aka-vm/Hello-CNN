{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test-Split\n",
    "\n",
    "This notebooks splits the dataset into train and test dataset.\n",
    "\n",
    "### Input Data Format: \n",
    "* DATA_PATH/<CLASS_Name>/<Image>.jpg\n",
    "\n",
    "### Output Data Format: \n",
    "* DATA_PATH/train/<CLASS_Name>/<Image>.jpg\n",
    "* DATA_PATH/test/<CLASS_Name>/<Image>.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "import sys"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go to parent directory\n",
    "os.chdir(\"..\")\n",
    "import paths\n",
    "\n",
    "REPO_DIR = paths.get_repo_path()\n",
    "ROOT_DIR = REPO_DIR / \"Stanford Dogs\"\n",
    "DATA_BASE_PATH = paths.get_data_path() / \"stanford-dogs-dataset\"\n",
    "DATA_PATH_IN = DATA_BASE_PATH / \"images/Images\"\n",
    "DATA_PATH_OUT = DATA_BASE_PATH / \"splited-data\"\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# set path to repo_dir\n",
    "os.chdir(REPO_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = 0.75"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naming Conventions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120,\n",
       " ['n02085620-Chihuahua',\n",
       "  'n02085782-Japanese_spaniel',\n",
       "  'n02085936-Maltese_dog',\n",
       "  'n02086079-Pekinese',\n",
       "  'n02086240-Shih-Tzu',\n",
       "  'n02086646-Blenheim_spaniel',\n",
       "  'n02086910-papillon',\n",
       "  'n02087046-toy_terrier',\n",
       "  'n02087394-Rhodesian_ridgeback',\n",
       "  'n02088094-Afghan_hound'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_dir = sorted(os.listdir(DATA_PATH_IN))\n",
    "try:\n",
    "    classes_dir.remove(\".DS_Store\")\n",
    "except ValueError:\n",
    "    pass\n",
    "len(classes_dir), classes_dir[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120,\n",
       " ['Chihuahua',\n",
       "  'Japanese Spaniel',\n",
       "  'Maltese Dog',\n",
       "  'Pekinese',\n",
       "  'Shih Tzu',\n",
       "  'Blenheim Spaniel',\n",
       "  'Papillon',\n",
       "  'Toy Terrier',\n",
       "  'Rhodesian Ridgeback',\n",
       "  'Afghan Hound'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_classes_names = []\n",
    "for image_class in classes_dir:\n",
    "    cls = image_class.replace(\"_\", \"-\").split(\"-\")\n",
    "    cls = \" \".join(cls[1:])\n",
    "    new_classes_names.append(cls.title())\n",
    "    \n",
    "len(new_classes_names), new_classes_names[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy images to new folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size: 15394\n",
      "test set size: 5186\n"
     ]
    }
   ],
   "source": [
    "# create folders for train, test\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "train_images_num = 0\n",
    "test_images_num = 0\n",
    "\n",
    "train_set_location = DATA_PATH_OUT / \"train\"\n",
    "os.makedirs(train_set_location, exist_ok=True)\n",
    "test_set_location = DATA_PATH_OUT / \"test\"\n",
    "os.makedirs(test_set_location, exist_ok=True)\n",
    "\n",
    "for i, image_class in enumerate(classes_dir):\n",
    "    image_class_path = DATA_PATH_IN / image_class\n",
    "    images = sorted(os.listdir(image_class_path))\n",
    "    \n",
    "    try :\n",
    "        images.remove(\".DS_Store\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    train_set_size = int(len(images) * train_test_split)\n",
    "    train_set_images = np.random.choice(images, train_set_size, replace=False)\n",
    "    test_set_images = [image for image in images if image not in train_set_images]\n",
    "    \n",
    "    train_images_num+=train_set_size\n",
    "    test_images_num+=len(test_set_images)\n",
    "    \n",
    "    train_set_class_path = train_set_location / new_classes_names[i]\n",
    "    test_set_class_path = test_set_location / new_classes_names[i]\n",
    "    \n",
    "    # if folders exist, delete them\n",
    "    if os.path.exists(train_set_class_path):\n",
    "        shutil.rmtree(train_set_class_path)\n",
    "    if os.path.exists(test_set_class_path):\n",
    "        shutil.rmtree(test_set_class_path)\n",
    "    \n",
    "    # create folders for class in train and test\n",
    "    os.makedirs(train_set_class_path, exist_ok=True)\n",
    "    os.makedirs(test_set_class_path, exist_ok=True)\n",
    "    \n",
    "    # copy images to train and test\n",
    "    for image in train_set_images:\n",
    "        image_path = image_class_path / image\n",
    "        shutil.copy(image_path, train_set_class_path)\n",
    "    for image in test_set_images:\n",
    "        image_path = image_class_path / image\n",
    "        shutil.copy(image_path, test_set_class_path)\n",
    "        \n",
    "print(\"train set size:\", train_images_num)\n",
    "print(\"test set size:\", test_images_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import dump\n",
    "\n",
    "test_train_info = {\n",
    "    \"total_train_images\": train_images_num,\n",
    "    \"total_test_images\": test_images_num,\n",
    "}\n",
    "\n",
    "with open(DATA_PATH_OUT / \"test_train_info.json\", \"w\") as f:\n",
    "    dump(test_train_info, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n02116738_10024.jpg',\n",
       " 'n02116738_10038.jpg',\n",
       " 'n02116738_10081.jpg',\n",
       " 'n02116738_10169.jpg',\n",
       " 'n02116738_10215.jpg',\n",
       " 'n02116738_10469.jpg',\n",
       " 'n02116738_10476.jpg',\n",
       " 'n02116738_10493.jpg',\n",
       " 'n02116738_10575.jpg',\n",
       " 'n02116738_10614.jpg',\n",
       " 'n02116738_10640.jpg',\n",
       " 'n02116738_10872.jpg',\n",
       " 'n02116738_10895.jpg',\n",
       " 'n02116738_1097.jpg',\n",
       " 'n02116738_1105.jpg']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(os.listdir(image_class_path))[:15]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit ('env_tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5a1ae6899980971a482c9ba4350aa5d29248927543f8d54686f28fa951765f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
