{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../input/digit-recognizer\"\n",
    "is_kaggle = os.path.isdir(data_dir)\n",
    "if is_kaggle:\n",
    "    ROOT_DIR = pathlib.Path(\"..\")\n",
    "    DATA_DIR = ROOT_DIR / \"input/digit-recognizer\"\n",
    "    SUBMISSION_PATH = ROOT_DIR / \"submissions.csv\"\n",
    "    MODELS_DIR = ROOT_DIR \n",
    "    \n",
    "else:\n",
    "    ROOT_DIR = pathlib.Path(\".\")\n",
    "    SUBMISSION_PATH = \"./submissions/mnist.csv\"\n",
    "    MODELS_DIR = ROOT_DIR / \"models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(use_extra_data=False) -> tuple[tuple, tuple]:\n",
    "    if is_kaggle:\n",
    "        input_data = pd.read_csv(DATA_DIR / \"train.csv\")\n",
    "        input_X = input_data.drop(\"label\", axis=1).values\n",
    "        input_X = input_X.reshape(-1, 28, 28)\n",
    "        input_labels = input_data[\"label\"].values\n",
    "        input_data = (input_X, input_labels)\n",
    "        \n",
    "        final_test_data = pd.read_csv(DATA_DIR / \"test.csv\")\n",
    "        final_test_X = final_test_data.values\n",
    "        final_test_X = final_test_X.reshape(-1, 28, 28)\n",
    "        final_test_data = (final_test_X, np.array([0]))\n",
    "        \n",
    "        if use_extra_data:\n",
    "            (train_X_tf, train_labels_tf), (test_X_tf, test_labels_tf) = tf.keras.datasets.mnist.load_data()\n",
    "            \n",
    "            input_X = np.concatenate([input_X, train_X_tf, test_X_tf])\n",
    "            input_labels = np.concatenate([input_labels, train_labels_tf, test_labels_tf])\n",
    "            \n",
    "    else:\n",
    "        input_data, final_test_data = tf.keras.datasets.mnist.load_data()\n",
    "        \n",
    "    return input_data, final_test_data\n",
    "\n",
    "(train_X, train_y), (test_X, test_y) = load_data()\n",
    "\n",
    "data_size = sum(map(sys.getsizeof, [train_X, test_X])) // 1024 ** 2\n",
    "print(\"Size of loaded data - \",data_size, \"MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "#reshape\n",
    "train_X = train_X.reshape(*train_X.shape[:3], 1)\n",
    "test_X = test_X.reshape(*test_X.shape[:3], 1)\n",
    "\n",
    "# OHE labels\n",
    "train_y_ohe = to_categorical(train_y)\n",
    "test_y_ohe = to_categorical(test_y)\n",
    "\n",
    "train_X.shape, train_y_ohe.shape, test_X.shape, test_y_ohe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_image_genetator = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    \n",
    "    height_shift_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    rotation_range=1,\n",
    "    shear_range=0.1,\n",
    "    brightness_range=[0.1, 1.1],\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "val_image_genetator = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    "    )\n",
    "\n",
    "test_image_genetator = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "\n",
    "train_images = train_image_genetator.flow(\n",
    "        train_X, train_y_ohe,\n",
    "        batch_size=64,\n",
    "        shuffle=True,\n",
    "        seed=42,\n",
    "        subset='training',\n",
    ")\n",
    "val_images = val_image_genetator.flow(\n",
    "        train_X, train_y_ohe,\n",
    "        batch_size=64,\n",
    "        seed=42,\n",
    "        subset='validation',\n",
    ")\n",
    "if is_kaggle:\n",
    "    test_images = test_image_genetator.flow(\n",
    "        test_X,\n",
    "        batch_size=64,\n",
    "        seed=42,\n",
    "        shuffle=False,\n",
    "    )\n",
    "else:\n",
    "    test_images = test_image_genetator.flow(\n",
    "        test_X, test_y_ohe,\n",
    "        batch_size=64,\n",
    "        seed=42,\n",
    "        shuffle=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the first image in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display images in a grid function\n",
    "def display_image_grid(images, labels, pred_val=None,shape=(5, 5), figsize=(10, 10)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    m = shape[0] * shape[1]\n",
    "    \n",
    "    if images.shape[0] < m:\n",
    "        raise ValueError(\"images.shape[0] must equal shape[0] * shape[1]\")\n",
    "    \n",
    "    for i in range(m):\n",
    "        plt.subplot(shape[0], shape[1], i+1)\n",
    "        plt.imshow(images[i], cmap=\"gray\", interpolation=\"none\")\n",
    "        title = labels[i]\n",
    "        if pred_val is not None:\n",
    "            title = f\"{pred_val[i]}\"\n",
    "            if pred_val[i] != labels[i]:\n",
    "                title += f\"\\n*({labels[i]})*\"\n",
    "        plt.title(title)\n",
    "        plt.axis(\"off\")\n",
    "        # increase vertical space between subplots\n",
    "        plt.subplots_adjust(wspace=0.1, hspace=0.4)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unaugmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_pts = np.random.randint(0, train_X.shape[0], 64)\n",
    "images = train_X[rnd_pts, :, :]\n",
    "labels = train_y[rnd_pts]\n",
    "\n",
    "display_image_grid(images, labels, shape=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = train_images.next()\n",
    "display_image_grid(images, labels.argmax(axis=1), shape=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, log_loss\n",
    "\n",
    "# ploting the model training history\n",
    "\n",
    "def plot_model_performance(history, figsize=(10, 10)):\n",
    "    preformance = {key: val for key, val in history.history.items() if \"loss\" not in key}\n",
    "    losses = {key: val for key, val in history.history.items() if \"loss\" in key}\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.title('Model Performance')\n",
    "    for key, val in preformance.items():\n",
    "        plt.plot(val, label=key)\n",
    "    plt.legend(preformance.keys())\n",
    "    plt.xlabel('Epoch')\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.title('Model Losses')\n",
    "    for key, val in losses.items():\n",
    "        plt.plot(val, label=key)\n",
    "    plt.legend(losses.keys())\n",
    "    plt.xlabel('Epoch')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def compute_performance_metrics(y, y_pred, verbose=1):\n",
    "    # labels = test_images_.y.argmax(axis=1)\n",
    "    labels = y.argmax(axis=1)\n",
    "    labels_cat = y\n",
    "    # pred_cat = model.predict(test_images_)\n",
    "    pred_cat = y_pred\n",
    "    pred = pred_cat.argmax(axis=1)\n",
    "\n",
    "    \n",
    "    performance_metrics = {}\n",
    "    performance_metrics[\"accuracy\"] = round(accuracy_score(labels, pred), 4)\n",
    "    performance_metrics[\"f1_score\"] = round(f1_score(labels, pred, average=\"macro\"), 4)\n",
    "    performance_metrics[\"precision\"] = round(precision_score(labels, pred, average=\"macro\"), 4)\n",
    "    performance_metrics[\"recall\"] = round(recall_score(labels, pred, average=\"macro\"), 4)\n",
    "    performance_metrics[\"loss\"] = round(log_loss(labels_cat, pred_cat), 4)\n",
    "    \n",
    "    performance_df.loc[model.name] = performance_metrics\n",
    "    if verbose:\n",
    "        return performance_df.loc[model.name]\n",
    "\n",
    "performance_df = pd.DataFrame(columns=[\"accuracy\", \"precision\", \"recall\", \"f1_score\", \"loss\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint\n",
    "\n",
    "monitor_metric = 'val_loss'\n",
    "learning_rate_decay_rate = 0.1\n",
    "\n",
    "def get_callbacks():\n",
    "    callbacks = {}\n",
    "    \n",
    "    callbacks[\"EarlyStopping\"] = EarlyStopping(\n",
    "            monitor=monitor_metric,\n",
    "            patience=5,\n",
    "            mode = \"auto\",\n",
    "            verbose=1,\n",
    "        )\n",
    "    \n",
    "    callbacks[\"LearningRateScheduler\"] = LearningRateScheduler(step_decay)\n",
    "\n",
    "    callbacks[\"ModelCheckpoint\"] = ModelCheckpoint(\n",
    "            MODELS_DIR / f\"{model.name}.h5\",\n",
    "            monitor=monitor_metric,\n",
    "            save_best_only=True,\n",
    "            mode='auto',\n",
    "            verbose=1,\n",
    "    )\n",
    "    \n",
    "    return callbacks\n",
    "\n",
    "def step_decay(epoch):\n",
    "    initial_lr = LEARNING_RATE\n",
    "    k = learning_rate_decay_rate\n",
    "    lr = initial_lr * np.exp(-k*epoch)\n",
    "    return lr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "def simple_sequential_model(input_shape, name=\"SimpleSequentialModel\"):\n",
    "    model = Sequential(name=name)\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape, padding=\"same\"))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape, padding=\"same\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding=\"same\"))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding=\"same\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = simple_sequential_model(input_shape=(28, 28, 1), name=\"mnist-digits-SimpleSequentialModel\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_path = MODELS_DIR / f\"{model.name}.h5\"\n",
    "\n",
    "train_model = not (os.path.exists(model_path))\n",
    "train_model = True\n",
    "\n",
    "LEARNING_RATE = 5e-4\n",
    "\n",
    "callbacks = [callback for callback in get_callbacks().values()]\n",
    "\n",
    "if train_model:\n",
    "    history = model.fit(train_images, \n",
    "                        validation_data=val_images,\n",
    "                        epochs=5, \n",
    "                        callbacks=callbacks,                        \n",
    "    )\n",
    "else:\n",
    "    model = load_model(model_path)\n",
    "    print(f\"{model.name} model loaded from {model_path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_performance(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_kaggle:\n",
    "    pass\n",
    "\n",
    "else:\n",
    "    model.evaluate(test_images)\n",
    "    test_labels = test_images.y\n",
    "    test_labels_pred_ohe = model.predict(test_images)\n",
    "    test_labels_pred = test_labels_pred_ohe.argmax(axis=1)\n",
    "    compute_performance_metrics(test_labels, test_labels_pred_ohe, True)\n",
    "\n",
    "\n",
    "performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.argmax(axis=1)[rnd_pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting only the incorrect images\n",
    "# Plotting only the incorrect images\n",
    "if is_kaggle:\n",
    "    labels_pred = model.predict(test_images)\n",
    "    test_labels_pred = test_labels_pred_ohe.argmax(axis=1)\n",
    "    \n",
    "    submission_df = pd.DataFrame(columns=[\"ImageId\", \"Label\"])\n",
    "    submission_df[\"ImageId\"] = range(1, len(test_labels_pred) + 1)\n",
    "    submission_df[\"Label\"] = test_labels_pred\n",
    "    submission_df.to_csv(SUBMISSION_PATH, index=False)\n",
    "    \n",
    "    \n",
    "labels_pred = test_labels_pred\n",
    "incorrect_pred = np.not_equal(test_labels.argmax(axis=1), test_labels_pred)\n",
    "incorrect_pred_index = np.where(incorrect_pred)[0]\n",
    "\n",
    "rnd_pts = np.random.choice(incorrect_pred_index, 25)\n",
    "\n",
    "images = test_X[rnd_pts, :, :]\n",
    "labels = test_labels.argmax(axis=1)[rnd_pts]\n",
    "labels_pred = labels_pred[rnd_pts]\n",
    "\n",
    "display_image_grid(test_X, labels, labels_pred, shape=(5, 5), figsize=(12, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageId\n",
    "# Label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('env_tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5a1ae6899980971a482c9ba4350aa5d29248927543f8d54686f28fa951765f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
